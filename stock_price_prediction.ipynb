{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata=quandl.get(\"NSE/PFC\")#,start_date=\"2005-12-01\",end_date=\"2005-12-05\")#toDo:NSE/SBIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2692\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Last</th>\n",
       "      <th>Close</th>\n",
       "      <th>Total Trade Quantity</th>\n",
       "      <th>Turnover (Lacs)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-28</th>\n",
       "      <td>121.90</td>\n",
       "      <td>121.90</td>\n",
       "      <td>119.25</td>\n",
       "      <td>119.75</td>\n",
       "      <td>119.85</td>\n",
       "      <td>5958794.0</td>\n",
       "      <td>7171.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-29</th>\n",
       "      <td>120.40</td>\n",
       "      <td>122.50</td>\n",
       "      <td>120.10</td>\n",
       "      <td>121.50</td>\n",
       "      <td>121.75</td>\n",
       "      <td>4736779.0</td>\n",
       "      <td>5762.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>121.40</td>\n",
       "      <td>125.50</td>\n",
       "      <td>121.30</td>\n",
       "      <td>124.00</td>\n",
       "      <td>123.80</td>\n",
       "      <td>6640773.0</td>\n",
       "      <td>8232.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>124.95</td>\n",
       "      <td>125.70</td>\n",
       "      <td>122.25</td>\n",
       "      <td>123.40</td>\n",
       "      <td>123.65</td>\n",
       "      <td>5576051.0</td>\n",
       "      <td>6916.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>124.50</td>\n",
       "      <td>124.75</td>\n",
       "      <td>123.05</td>\n",
       "      <td>123.85</td>\n",
       "      <td>123.75</td>\n",
       "      <td>3126273.0</td>\n",
       "      <td>3872.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low    Last   Close  Total Trade Quantity  \\\n",
       "Date                                                                       \n",
       "2017-12-28  121.90  121.90  119.25  119.75  119.85             5958794.0   \n",
       "2017-12-29  120.40  122.50  120.10  121.50  121.75             4736779.0   \n",
       "2018-01-01  121.40  125.50  121.30  124.00  123.80             6640773.0   \n",
       "2018-01-02  124.95  125.70  122.25  123.40  123.65             5576051.0   \n",
       "2018-01-03  124.50  124.75  123.05  123.85  123.75             3126273.0   \n",
       "\n",
       "            Turnover (Lacs)  \n",
       "Date                         \n",
       "2017-12-28          7171.80  \n",
       "2017-12-29          5762.32  \n",
       "2018-01-01          8232.74  \n",
       "2018-01-02          6916.36  \n",
       "2018-01-03          3872.41  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(mydata))\n",
    "mydata.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data from Quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(symbol, start_date, end_date):\n",
    "    data=quandl.get(symbol, start_date = start_date, end_date = end_date)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df):\n",
    "    \"\"\"\n",
    "    Input Dataframe Columns : Open, Close, High, Low, Volume, Adjusted Close\n",
    "    Output Dataframe Columns : Same columns as Input and new features\n",
    "    \"\"\"\n",
    "    df_new=pd.DataFrame()\n",
    "    df_new['open']=df['Open']\n",
    "    #print(df['Open'].head())\n",
    "    df_new['open_1']=df['Open'].shift(1)\n",
    "    \n",
    "    df_new['close_1']=df['Close'].shift(1)\n",
    "    #print(df['Close'].head())\n",
    "    df_new['high_1']=df['High'].shift(1)\n",
    "    df_new['low_1']=df['Low'].shift(1)\n",
    "    df_new['volume_1']=df['Total Trade Quantity'].shift(1)\n",
    "    \n",
    "    df_new['avg_price_5']=pd.rolling_mean(df['Close'],window=5).shift(1)\n",
    "    df_new['avg_price_30']=pd.rolling_mean(df['Close'],window=21).shift(1)\n",
    "    df_new['avg_price_365']=pd.rolling_mean(df['Close'],window=252).shift(1)\n",
    "    \n",
    "    df_new['ratio_avg_price_5_30']=df_new['avg_price_5']/df_new['avg_price_30']\n",
    "    df_new['ratio_avg_price_5_365']=df_new['avg_price_5']/df_new['avg_price_365']\n",
    "    df_new['ratio_avg_price_30_365']=df_new['avg_price_30']/df_new['avg_price_365']\n",
    "    \n",
    "    df_new['avg_volume_5']=pd.rolling_mean(df['Total Trade Quantity'],window=5).shift(1)\n",
    "    df_new['avg_volume_30']=pd.rolling_mean(df['Total Trade Quantity'],window=21).shift(1)\n",
    "    df_new['avg_volume_365']=pd.rolling_mean(df['Total Trade Quantity'],window=252).shift(1)\n",
    "    \n",
    "    df_new['ratio_avg_volume_5_30']=df_new['avg_volume_5']/df_new['avg_volume_30']\n",
    "    df_new['ratio_avg_volume_5_365']=df_new['avg_volume_5']/df_new['avg_volume_365']\n",
    "    df_new['ratio_avg_volume_30_365']=df_new['avg_volume_30']/df_new['avg_volume_365']\n",
    "    \n",
    "    df_new['std_price_5']=pd.rolling_std(df['Close'],window=5).shift(1)\n",
    "    df_new['std_price_30']=pd.rolling_std(df['Close'],window=21).shift(1)\n",
    "    df_new['std_price_365']=pd.rolling_std(df['Close'],window=252).shift(1)\n",
    "    \n",
    "    df_new['ratio_std_price_5_30']=df_new['std_price_5']/df_new['std_price_30']\n",
    "    df_new['ratio_std_price_5_365']=df_new['std_price_5']/df_new['std_price_365']\n",
    "    df_new['ratio_std_price_30_365']=df_new['std_price_30']/df_new['std_price_365']\n",
    "    \n",
    "    df_new['std_volume_5'] = pd.rolling_std(df['Total Trade Quantity'],window=5).shift(1)\n",
    "    df_new['std_volume_30'] = pd.rolling_std(df['Total Trade Quantity'],window=21).shift(1)\n",
    "    df_new['std_volume_365'] = pd.rolling_std(df['Total Trade Quantity'],window=252).shift(1)\n",
    "    \n",
    "    df_new['ratio_std_Volume_5_30'] = df_new['std_volume_5']/df_new['std_volume_30']\n",
    "    df_new['ratio_std_Volume_5_365'] = df_new['std_volume_5']/df_new['std_volume_365']\n",
    "    df_new['ratio_std_Volume_30_365'] = df_new['std_volume_30']/df_new['std_volume_365']\n",
    "    \n",
    "    df_new['return_1'] = ((df['Close']-df['Close'].shift(1))/df['Close'].shift(1)).shift(1)\n",
    "    df_new['return_5'] = ((df['Close']-df['Close'].shift(5))/df['Close'].shift(5)).shift(1)\n",
    "    df_new['return_30'] = ((df['Close']-df['Close'].shift(21))/df['Close'].shift(21)).shift(1)\n",
    "    df_new['return_365'] = ((df['Close']-df['Close'].shift(252))/df['Close'].shift(252)).shift(1)\n",
    "    \n",
    "    df_new['moving_avg_5'] = pd.rolling_mean(df_new['return_1'], window=5)\n",
    "    df_new['moving_avg_30'] = pd.rolling_mean(df_new['return_1'], window=21)\n",
    "    df_new['moving_avg_365'] = pd.rolling_mean(df_new['return_1'], window=252)\n",
    "    \n",
    "    df_new['close'] = df['Close']\n",
    "    df_new = df_new.dropna(axis=0)\n",
    "    \n",
    "    return df_new\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=generate_features(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>open_1</th>\n",
       "      <th>close_1</th>\n",
       "      <th>high_1</th>\n",
       "      <th>low_1</th>\n",
       "      <th>volume_1</th>\n",
       "      <th>avg_price_5</th>\n",
       "      <th>avg_price_30</th>\n",
       "      <th>avg_price_365</th>\n",
       "      <th>ratio_avg_price_5_30</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_std_Volume_5_365</th>\n",
       "      <th>ratio_std_Volume_30_365</th>\n",
       "      <th>return_1</th>\n",
       "      <th>return_5</th>\n",
       "      <th>return_30</th>\n",
       "      <th>return_365</th>\n",
       "      <th>moving_avg_5</th>\n",
       "      <th>moving_avg_30</th>\n",
       "      <th>moving_avg_365</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-02-25</th>\n",
       "      <td>188.00</td>\n",
       "      <td>191.5</td>\n",
       "      <td>185.00</td>\n",
       "      <td>193.00</td>\n",
       "      <td>184.20</td>\n",
       "      <td>721729.0</td>\n",
       "      <td>190.62</td>\n",
       "      <td>186.216667</td>\n",
       "      <td>183.499802</td>\n",
       "      <td>1.023646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317346</td>\n",
       "      <td>0.270635</td>\n",
       "      <td>-0.041451</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>-0.001350</td>\n",
       "      <td>0.656964</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>191.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-26</th>\n",
       "      <td>192.50</td>\n",
       "      <td>188.0</td>\n",
       "      <td>191.35</td>\n",
       "      <td>192.00</td>\n",
       "      <td>182.05</td>\n",
       "      <td>459217.0</td>\n",
       "      <td>191.32</td>\n",
       "      <td>186.078571</td>\n",
       "      <td>183.801587</td>\n",
       "      <td>1.028168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379356</td>\n",
       "      <td>0.306315</td>\n",
       "      <td>0.034324</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>-0.014929</td>\n",
       "      <td>0.659584</td>\n",
       "      <td>0.004095</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>190.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-27</th>\n",
       "      <td>193.50</td>\n",
       "      <td>192.5</td>\n",
       "      <td>190.95</td>\n",
       "      <td>194.00</td>\n",
       "      <td>188.00</td>\n",
       "      <td>422143.0</td>\n",
       "      <td>190.69</td>\n",
       "      <td>185.880952</td>\n",
       "      <td>184.093452</td>\n",
       "      <td>1.025872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149538</td>\n",
       "      <td>0.335509</td>\n",
       "      <td>-0.002090</td>\n",
       "      <td>-0.016229</td>\n",
       "      <td>-0.021271</td>\n",
       "      <td>0.626491</td>\n",
       "      <td>-0.002978</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.002670</td>\n",
       "      <td>191.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-28</th>\n",
       "      <td>191.00</td>\n",
       "      <td>193.5</td>\n",
       "      <td>191.30</td>\n",
       "      <td>197.75</td>\n",
       "      <td>187.60</td>\n",
       "      <td>829135.0</td>\n",
       "      <td>190.32</td>\n",
       "      <td>185.604762</td>\n",
       "      <td>184.411905</td>\n",
       "      <td>1.025405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112792</td>\n",
       "      <td>0.345099</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>-0.009578</td>\n",
       "      <td>-0.029427</td>\n",
       "      <td>0.722647</td>\n",
       "      <td>-0.001632</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>180.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-29</th>\n",
       "      <td>180.75</td>\n",
       "      <td>191.0</td>\n",
       "      <td>180.75</td>\n",
       "      <td>192.00</td>\n",
       "      <td>176.75</td>\n",
       "      <td>2720964.0</td>\n",
       "      <td>187.87</td>\n",
       "      <td>184.892857</td>\n",
       "      <td>184.690476</td>\n",
       "      <td>1.016102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437778</td>\n",
       "      <td>0.366976</td>\n",
       "      <td>-0.055149</td>\n",
       "      <td>-0.063472</td>\n",
       "      <td>-0.076392</td>\n",
       "      <td>0.635007</td>\n",
       "      <td>-0.012507</td>\n",
       "      <td>-0.002184</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>187.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              open  open_1  close_1  high_1   low_1   volume_1  avg_price_5  \\\n",
       "Date                                                                          \n",
       "2008-02-25  188.00   191.5   185.00  193.00  184.20   721729.0       190.62   \n",
       "2008-02-26  192.50   188.0   191.35  192.00  182.05   459217.0       191.32   \n",
       "2008-02-27  193.50   192.5   190.95  194.00  188.00   422143.0       190.69   \n",
       "2008-02-28  191.00   193.5   191.30  197.75  187.60   829135.0       190.32   \n",
       "2008-02-29  180.75   191.0   180.75  192.00  176.75  2720964.0       187.87   \n",
       "\n",
       "            avg_price_30  avg_price_365  ratio_avg_price_5_30   ...    \\\n",
       "Date                                                            ...     \n",
       "2008-02-25    186.216667     183.499802              1.023646   ...     \n",
       "2008-02-26    186.078571     183.801587              1.028168   ...     \n",
       "2008-02-27    185.880952     184.093452              1.025872   ...     \n",
       "2008-02-28    185.604762     184.411905              1.025405   ...     \n",
       "2008-02-29    184.892857     184.690476              1.016102   ...     \n",
       "\n",
       "            ratio_std_Volume_5_365  ratio_std_Volume_30_365  return_1  \\\n",
       "Date                                                                    \n",
       "2008-02-25                0.317346                 0.270635 -0.041451   \n",
       "2008-02-26                0.379356                 0.306315  0.034324   \n",
       "2008-02-27                0.149538                 0.335509 -0.002090   \n",
       "2008-02-28                0.112792                 0.345099  0.001833   \n",
       "2008-02-29                0.437778                 0.366976 -0.055149   \n",
       "\n",
       "            return_5  return_30  return_365  moving_avg_5  moving_avg_30  \\\n",
       "Date                                                                       \n",
       "2008-02-25  0.003254  -0.001350    0.656964      0.000972       0.001491   \n",
       "2008-02-26  0.018632  -0.014929    0.659584      0.004095       0.000812   \n",
       "2008-02-27 -0.016229  -0.021271    0.626491     -0.002978       0.000504   \n",
       "2008-02-28 -0.009578  -0.029427    0.722647     -0.001632       0.000104   \n",
       "2008-02-29 -0.063472  -0.076392    0.635007     -0.012507      -0.002184   \n",
       "\n",
       "            moving_avg_365   close  \n",
       "Date                                \n",
       "2008-02-25        0.002744  191.35  \n",
       "2008-02-26        0.002750  190.95  \n",
       "2008-02-27        0.002670  191.30  \n",
       "2008-02-28        0.002892  180.75  \n",
       "2008-02-29        0.002691  187.45  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prediction(X, weights):\n",
    "    \"\"\"\n",
    "    calculate y_hat\n",
    "    \"\"\"\n",
    "    predictions = np.dot(X, weights)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(X_train, y_train, weights, learning_rate):\n",
    "    \"\"\"\n",
    "    Update weights\n",
    "    \"\"\"\n",
    "    predictions = compute_prediction(X_train, weights)\n",
    "    weights_delta = np.dot(X_train.T, y_train - predictions)\n",
    "    m = y_train.shape[0]\n",
    "    weights += learning_rate/float(m)*weights_delta\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, weights):\n",
    "    \"\"\"\n",
    "    COst\n",
    "    \"\"\"\n",
    "    predictions = compute_prediction(X, weights)\n",
    "    cost = np.mean((predictions-y)**2/2.0)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X_train, y_train, max_iter, learning_rate, fit_intercept=False):\n",
    "    \"\"\"\n",
    "    Training Linear Regression\n",
    "    \"\"\"\n",
    "    if fit_intercept:\n",
    "        intercept = np.ones((X_train.shape[0],1))\n",
    "        X_train = np.hstack((intercept, X_train))\n",
    "    weights = np.zeros(X_train.shape[1])\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        weights = update_weights(X_train, y_train, weights, learning_rate)\n",
    "        if iteration%100 == 0:\n",
    "            print(compute_cost(X_train, y_train, weights))\n",
    "    return weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights):\n",
    "    if X.shape[1] == weights.shape[0]-1:\n",
    "        intercept = np.ones((X.shape[0],1))\n",
    "        X = np.hstack((intercept,X))\n",
    "    return compute_prediction(X, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "sd=datetime.datetime(2007, 2, 23, 0, 0)\n",
    "ed=datetime.datetime(2017, 11, 23, 0, 0)\n",
    "result_subset=result.ix[sd:ed]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_col=result.drop(['close'],axis=1).columns\n",
    "y_col = 'close'\n",
    "X_train = result_subset[X_col]\n",
    "y_train = result_subset[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2411, 37)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2411,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd1=datetime.datetime(2017, 11, 24, 0, 0)\n",
    "ed1=datetime.datetime(2018, 1, 3, 0, 0)\n",
    "result_subset1=result.ix[sd1:ed1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=result_subset1[X_col]\n",
    "y_test=result_subset1[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 37)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"alpha\": [3e-06, 1e-5, 3e-5],\n",
    "    \"eta0\": [0.01, 0.03, 0.1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "lr=linear_model.SGDRegressor(penalty='l2', n_iter=1000)\n",
    "grid_search = GridSearchCV(lr, param_grid, cv=5, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/akash/Desktop/Projects/sppr/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', max_iter=None, n_iter=1000, penalty='l2',\n",
       "       power_t=0.25, random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'eta0': [0.01, 0.03, 0.1], 'alpha': [3e-06, 1e-05, 3e-05]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eta0': 0.01, 'alpha': 3e-05}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_best=grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=lr_best.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.248\n",
      "MSE: 1.188\n",
      "MSE: 0.737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print('MSE: {0:.3f}'.format(mean_squared_error(y_test, predictions)))\n",
    "print('MSE: {0:.3f}'.format(mean_absolute_error(y_test, predictions)))\n",
    "print('MSE: {0:.3f}'.format(r2_score(y_test, predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa8a02f4cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test.plot()\n",
    "output=y_test.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=output.to_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['prediction']=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-28</th>\n",
       "      <td>119.85</td>\n",
       "      <td>122.097261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-29</th>\n",
       "      <td>121.75</td>\n",
       "      <td>120.636038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>123.80</td>\n",
       "      <td>122.065192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>123.65</td>\n",
       "      <td>125.150511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>123.75</td>\n",
       "      <td>124.766970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             close  prediction\n",
       "Date                          \n",
       "2017-12-28  119.85  122.097261\n",
       "2017-12-29  121.75  120.636038\n",
       "2018-01-01  123.80  122.065192\n",
       "2018-01-02  123.65  125.150511\n",
       "2018-01-03  123.75  124.766970"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sppr",
   "language": "python",
   "name": "sppr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
